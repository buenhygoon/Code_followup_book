{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursion is a technique by which a function makes one or more calls to itself during execution, or by which a data structure relies upon smaller instances of the very same type of structure in tis representation. There are many examples of recursion in art and nature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In computing recursion provides an elegant and powerful alternative for performing repetitive tasks. In fact, a few programming languages do not explicitly support looping constructs and instead rely directly on recursion to express repetition. Most modern programming languages support functional recursion using the identical mechanism that is used to support traditional forms of function calls. When one invovation of the function make a recursive call, that invocation is suspended until the recursive call completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The factorial function is a classic mathematical function that has a natural recursive definition.\n",
    "- An English ruler has a recursive pattern that is a simple example of a fractal structure.\n",
    "- Binary search is among the most important computer algorithms. It allows us to efficiently locate a desired value in a data set with upwards of billions of entries. \n",
    "- The file system for a computer has a recursive structure in which directories can be nested arbitrarily deeply within other directories. Recursive algorithms are widely used to explore and mange these file systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Illustrative Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.1.1 The Factorial Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To demonstrate the mechanics of recursion, we begin with a simple mathematical  example of computing the value of the factorial function. The factorial of a positive integer n, denoted n!, is defined as the product of the integers from 1 to n. If n = 0, then n! is defined as 1 by convention. More formally, for any integer n >= 0, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For exmaple, 5! = 5 \\* 4 \\* 3 \\* 2 * 1 = 120. The factorial function is important because it is known to equal the number of ways in which n distinct items can be arranged into a sequence, that is, the number of permutations of n items. For example, the three characters a, b and c can be arranged in 3! = 3 \\* 2 \\* 1 = 6 ways: abc, acb, bac, bca, cab and cba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a natural recursive definition for the factorial function. To see this, observe that 5! = 5 \\* (4 \\* 3 \\* 2 \\* 1) = 5 \\* 4!. More generally, for a positive integer n, we can define n! to be n \\* (n -1 )!. This recursive definition can be formalized as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This definition is typical of many recursive definitions. First, it contains one or more base cases, which are defined nonrecursively in terms of fixed quantities. In this case, n = 0 is the base case. It also contains one or more recursive cases, which are defined by appealing to the definition of the function beign defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A Recursive Implementation of the Factorial Function **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursion is not just a mathmatical notation: we can use recursion to design a Python implementation of a factorial function, as shown in Code Fragment 4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function does not use any explicit loops. Repetition is provided by the repeated recursive invocations of the function. There is no circularity in this definition, because each time the function is invoked, its argument is smaller by one, and when a base case is reached, no further recursive calls are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We illustrate the execution of a recursive function using a **recursive trace**. Each entry of the trace corresponds to a recursive call. Each new recursive function call is indicated by a downward arrow to a new invocation. When the function returns, an arrow showing this return is drawn and the return value may be indicated alongside this arrow. An example of such a trace for the factorial function is shown in Figure 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A recursion trace closely mirrors the programming language's execution of the recursion. In Python, each time a function is called, a structure known as an activation record or frame is created to store information about the progress of that invocation of the function. This activation record includes a namespace for storign the function call's parameters and local variables, and information about which command in the body of the function is currently executing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the execution of a function leads to a nested function call, the execution of the former call is suspended and its activation record stores the place in the source code at which the flow of control should continue upon return of the nested call. This process is used both in the standard case of function calling a different function, or in the recursive case in which a function invokes itself. The key point is that there is a different activation record for each active call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Drawing an English Ruler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the case of computing a factorial, there is no compelling reason for preferring recursion over a direct iteration with a loop. As a major complew example of the use of recursion, consider how to draw the markings of a typical English ruler. For each inch, we place a tick with a numeric label. We denote the length of the tick designating a whole inch as the major tick length. Between the marks for whole inches, the ruler contains a series of minor ticks, placed at intervals of 1/2 inch, 1/4 inch, and so on. As the size of the interval decreases by half, the tick length decreases by one/. Figure 4.2 demonstrates several such rulers with varying major tick lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A Recursive Approach to Ruler Drawing **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The English ruler pattern is a simple example of a fractal , that is, a shape that has a self-recursive structure at various levels of magnification. Consider the rule with major tick length 5 shown in Figure 4.2(b). Ignoring the lines containing 0 and 1, let us consider how to draw the sequence of tick lying between these lines. The central tick has length 4. Observe that the two patterns of ticks above and below this central tick are identical, and each has a central tick of length 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In general, an interval with a central tick length L >= 1 is composed of :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- An interval with a central tick length L-1\n",
    "- A single tick of length L\n",
    "- An interval with a central tick length L-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Although it is possible to draw such a ruler using an iterative process, the task is considerably easier to accomplish with recursion. Our implementation consists of three functions, as shown in Code Fragment 4.2. The main function, draw\\_ruler, manages the construction of the entire ruler. Its arguments specify the total number of inches in the ruler and the major tick length. The utility function, draw\\_line, draws a single tich with a specified number of dashes. \n",
    "- The interesting work is done by the recursive draw\\_interval function. This function draws the sequence of minor ticks within some interval, based upon the length of the interval's central tick. We rely on the intuition shown at the top of this last steps are performed by resursively calling draw\\_interval(L - 1). The middle step is performed by calling the function draw\\_line(L)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_line(tick_length, tick_label=''):\n",
    "    \"\"\"Draw one line with given tick length (followed by optional label).\"\"\"\n",
    "    line = '-' * tick_length\n",
    "    if tick_label:\n",
    "        line += ' ' + tick_label\n",
    "    print(line)\n",
    "    \n",
    "def draw_interval(center_length):\n",
    "    \"\"\"Draw tick interval based upon a central tick length.\"\"\"\n",
    "    if center_length > 0:\n",
    "        draw_interval(center_length - 1)\n",
    "        draw_line(center_length)\n",
    "        draw_interval(center_length - 1)\n",
    "        \n",
    "def draw_ruler(num_inches, major_length):\n",
    "    \"\"\"Draw Enlgish ruler with given number of inches, major tick length.\"\"\"\n",
    "    draw_line(major_length, '0')\n",
    "    for j in range(1, 1 + num_inches):\n",
    "        draw_interval(major_length - 1)\n",
    "        draw_line(major_length, str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Illustrating Ruler Drawing Using a Recursion Trace **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The execution of the recursive draw\\_interval function can be visualized using a recursion trace. The trace for draw\\_interval is more complicated than in the factorial example, however, because each instance makes two recursive calls. To illustrate this, we will show the recursion trace in a form that is reminiscent of an outline for a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Binary Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we describe a classic recursive algorithm, binary search, that is used to efficiently locate a target value within a sorted sequence of n elements. This is among the most inportant of computer algorithms, and it is the reason that we so often store data in sorted order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the sequence is unsorted, the standard approach to search for a target value is to use a loop to examine every element, until either finding the target or exhausting the data set. This is known as the sequential search algorithm. This algorithm runs in O(n) time since every element is inspected in the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the sequence is sorted and indexable, there is a much more efficient algorithm. For any index j, we know that all the values stored at indices 0, ... , j - 1 are less than or equal to the value at index j, and all the values stored at indices j + 1, ..., n - 1 are greater than or equal to that at index j. This observation allows us to quickly \"home in\" on a search target using a variant of the children's game \"high-low\". We call an element of the sequence a candidate if, at the current stage of the search, we cannot rule out that this item matches the target. The algorithm maintains two parameters, low and high, such that all the candidate entries have index at least low and at most high. Initailly, low = 0 and high = n - 1. We then compare the target value to the median candidate, that is , the item data[mid] with index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We consider three cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the target equals data[mid], then we have found the item we are looking for, and the search terminates successfully. \n",
    "- If target < data[mid], then we recur on the first half of the sequence, that  is, on the interval of indices from low to mid -1.\n",
    "- If target > data[mid], then we recur on the second half of the sequence, that is, on the interval of indices from mid + 1 to high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An unsuccessful search occurs if low > high, as the interval [low, high] is empty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This algorithm is known as binary search. We give a Python implementation in Code Fragment 4.3, and an illustration of the execution of the algorithm in Figure 4.5. Whereas sequential search runs in O(n) time, the more efficient binary search runs in O(log n) time. This is a significant improvement, given that if n is one billion, log n is only 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_search(data, target, low, high):\n",
    "    \"\"\"Return True if target is found in indicated portion of a Python list.\n",
    "    \n",
    "    The search only considers the portion from data[low] to data[high] inclusive.\n",
    "    \"\"\"\n",
    "    if low > high:\n",
    "        return False\n",
    "    else:\n",
    "        mid = (low + high) // 2\n",
    "        if target == data[mid]:\n",
    "            return True\n",
    "        elif target < data[mid]:\n",
    "            # recur on the portion left of the middle\n",
    "            return binary_search(data, target, low, mid - 1)\n",
    "        else:\n",
    "            # recur on the portion right of the middle\n",
    "            return binary_search(data, target, mid + 1, high)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 File Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modern operating systems define file-system directories (which are also sometimes called \"folders\") in a recursive way. Namely, a file system consists of a top-level directory, and the contents of this directory consists of files and other directories, which in turn can contain files and other directories, and so on. The operating system allows directories to be nested arbitrarily deep (as long as there is enough space in memory), although there must necessarily be some base directories that contain only files, not further subdirectories. A representation of a portion of such file system is given in Figure 4.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Given the recursive nature of the file-system representation, it should not come as a surprise that many common behaviors of an operating system, such as copying a directory or deleting a diretory, are implemented with recursive algorithms.** In this section, we consider one such algorithm: computing the total isk usage for all files and directories nested within a particular directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For illustration, Figure 4.7 portrays the disk space being used by all entries in our sample file system. We differentiate between the immediate disk space used by each entry and the cumulative disk space space used by that entry and all nested features. For example, the cs016 diretory uses only 2K of immediate space, but a total of 249K of cumulative space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cumulative disk spcae for an entry can be computed with a simple recursive algorithm. It is equal to the immediate disk space used by the entry plus the sum of the cumulative disk space usage of any entries that are stored directly within the entry. For example, cumulative disk space for cs016 is 249K because it uses 2K itself, 8K cumulatively in grades, 10K cumulatively homeworks, and 229K cumultively in programs. Pseudo-code for this algorithm is given in Code-Fragment 4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm DiskUsage(path):\n",
    "  Input: A string designating a path to a file-system entry\n",
    "  Output: The cumulative disk space used by that entry and any nested entries \n",
    "  total = size(path)\n",
    "  if path represents a directory then\n",
    "    for each child entry stored within directory path do\n",
    "      total = total + DistUsage(child)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Python's os Module **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- To provide a Python implementation of a recursive algorithm for computing disk usage, we rely on Python's os module, which provides robust tools for interacting with the operating system during the execution of a program. This is an extensive library, but we will only need the following four functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- os.path.getsize(path) : Return the immediate disk usage (measured in bytes) for the file or directory that is identified by the string path(e.g., /user/rt/courses).\n",
    "\n",
    "- os.path.isdir(path) : Return True if entry designated by string path is a directory; False otherwise.\n",
    "\n",
    "- os.listdir(path) : Return a list of string that are the names of all entries within a directory designated by string path. IN our sample file system, if the parameter is /user/rt//courses, this returns the list['cs016', 'cs252'].\n",
    "\n",
    "- os.path.join(path, filename) : Compose the path string and filename string using an appropriate operating system separator between the two(e.g., the / character for a Unix/Linux syste, and the \\ character for Windows). Return the string that represents the full path to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Python Implementation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def disk_usage(path):\n",
    "    \"\"\"Return the number of bytes used by a file/folder and any descendents.\"\"\"\n",
    "    total = os.path.getsize(path)\n",
    "    if os.path.isdir(path):\n",
    "        for filename in os.listdir(path):\n",
    "            childpath = os.path.join(path, filename)\n",
    "            total += disk_usage(childpath)\n",
    "    \n",
    "    print('{0:<7}'.format(total), path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26405   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch1_python_primer-checkpoint.ipynb\n",
      "49455   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch2_oop_20180223-checkpoint.ipynb\n",
      "33750   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch3_alorithm_analysis_20180226-checkpoint.ipynb\n",
      "18047   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch4_recursion_20180227-checkpoint.ipynb\n",
      "131753  /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints\n",
      "56428   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/bigoh_function.png\n",
      "26405   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch1_python_primer.ipynb\n",
      "49455   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch2_oop_20180223.ipynb\n",
      "33750   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch3_alorithm_analysis_20180226.ipynb\n",
      "21334   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch4_recursion_20180227.ipynb\n",
      "27712   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/classes_of_functions.png\n",
      "43795   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/function_parameter.png\n",
      "65677   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/inheritance.png\n",
      "460405  /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "460405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_usage('/home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recursion Trace **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To produce a different form of a recursion trace, we have included an extraneous print statement within our Python implementation. The precise format of that output intentionally mirros output that is produced by a classic Unix/Linux utility named du(for \"disk usage\"). It reports the amount of disk space used by a directory and all contents nested within, and can produce a verbose report, as given in Figure 4.8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our implementation of the disk\\_usage function produces an identical result, when executed on the sample file system portrayed in Figure 4.7. During the execution of the algorithm, exactly one recursive call is made for each entry in the portion of the file system that is considered. Because the print statement is made just before returning from a recursive call, the output shown in Figure 4.8 reflects the order in which the recursive calls are completed. In particular, we begin and end a recursive call for each entry that is nested below another entry, computing the nested cumulative disk space before we can compute and report the cumulative disk space for the containing entry. For example, we do not know the cumulative total for entry /user/rt/courses/cs016 until after the recursive calls regarding contained entries grades, homeworks, and programs complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Analyzing Recursive Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Chapter 3, we introduced mathematical techniques for analyzing the efficiency of an algorithm, based upon an estimate of the number of primitive operations that are executed by the algorithm. We use notations such as big-Oh to summarize the relationship between the number of operations and the input size for a problem. In this section, we demonstrate how to perform this type of running-time analysis to recursive algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a recursive algorithm, we will account for each operation that is performed based upon the particular activation of the function that manages the flow of control at the time it is executed. Stated another way, for each invocation of the function, we only account for the number of operations that are performed within the body of that activation. We can then account for the overall number of operations that are executed as part of the recursive algorithm by taking the sum, over all activations, of the number of operations that take place during each individual activation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- To demonstrate this style of analysis, we revisit the four recursive algorithms presented in Sections 4.1.1 through 4.1.4: factorial computation, drawing an English ruler, binary search, and computation of the cumulative size of a file system. In general, we may rely on the intuition afforded by a recursion trace in recognizing how many recursive activations occur, and how the parameterization of each activation can be used to estimate the number of primitive operations that occur within the body of that activation. However, each of these recursive algorithms has a unique structure and form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Computing Factorials **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is relatively easy to analyze the efficiency of our function for computing factorials, as described in Section 4.1.1. A sample recursion trace for our factorial function was given in Figure 4.1. To compute factorial(n), we see that there are a total of n + 1 activations, as the parameter decreases from n in the first call , to n - 1in the second call, and so on, until reaching the base with parameter 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is also clear, given as examination of the function body in Code Fragment 4.1, that each individual activation of factorial executes a constant number of operations. Therefore, we conclude that the overall number of operations for computing factorial(n) is O(n), as there are n + 1 activations, each of which accounts for O(1) operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Drawing an English Ruler **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In analyzing the English ruler application from Section 4.1.2, we consider the fundamental question of how many total lines of output are generated by an initial call to draw\\_interval(c), where c denotes the center length. This is a reasonable benchmark for the overall efficiency of the algorithm as each line of output is based upon a call to the draw\\_line utility, and each recursive call to draw\\_interval with nonzero parameter makes exactly one direct call to draw\\_line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some intuition may be gained by examining the source code and the recursion trace. We know that a call to draw\\_interval(c) for c>0 spawns two calls to draw\\_interval(c-1) and a single call to draw\\_line. We will rely on this intuition to prove the following claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justification**: We provide a formal proof of this claim by induction. In fact, induction is a natural mathematical technique for proving the correctness and efficiency of a recursive process. In the case of the ruler, we note that an application of draw\\_interval(0) generates no output, and that $2^0$ - 1 = 1 - 1 = 0. This serves as a base case for our claim. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performing a Binary Search **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considering the running time of the binary search algorithm, as presented in Section 4.1.3, we observe that a constant number of primitive operations are executed at each resursive call of method of a binary search. Hence, the running time is proportional to the number of recursive calls performed. We will show that at most [log n] + 1 recursive calls are made during a binary search of a sequence having n elements, leading to the following claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Justification: To prove this claim, a crucial fact is that with each recursive call the number of candidate entries still to be searched is given by the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ high - low + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moreover, the number of remaining candidates is reduced by at least one half with each recursive call. Specifically, from the definition of mid, the number of remaining candidates is either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initially, the number of candidates is n; after the first call in a binary search, it is at most n/2; after the second call, it is at most n/4; nad so on. In general, after the jth call in a binary search, the number of candidate entries remaining is at most n/2j. IN the worst case(an unsuccessful search), the recursive calls stop when there are no more candidate entries. Hence, the maximum number of recursive calls performed, is the smallest integer r such that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\dfrac{n}{2^r} < 1. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In other words (recalling that we omit a logrithm's base when it is 2), r > logn. Thus, we have "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ r = [\\log{n}] + 1, $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which implies that binary search runs in O(log n) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Computing Disk Space Usage **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our final recursive algorithm from Section 4.1 was that for computing the overall disk space usage in a specified portion of a file system. To characterize the \"problem size\" for our analysis, we let n denote the number of file-system entries in the portion of the file system that is considered. (For example, the file system portrayed in Figure 4.6 has n = 19 entries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To characterize the cumulative time spent for an initial call to the disk\\_usage function, we must analyze the total number of recursive invocations that are made, as well as the number of operations that are executed within those invocations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We begin by showing that there are precisely n recursive invocations of the function, in particular, one for each entry in the relevant portion of the file system. Intuitively, this is because a call to disk\\_usage for a particular entry e of the file system is only made from within the for loop of Code Fragment 4.5 when processing the entry for the unique directory that contains e, and that entry will only be explored once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To formalize this argument, we can define the nesting level of each entry such that the entry on which we begin has nesting level 0, entries stored directly within it have nesting level 1, entries stored within those entries have nesting level 2, and so on. We can prove by induction that there is exactly one recursive invocation of disk\\_usage upon each entry at nesting level k. As a base case, when k = 0, the only recursive invocation made is the initial one. As the inductive step, once we know there is exactly one recursive invocation for each entry at nesting level k, we can claim that there is exactly one invocation for each entry e at nesting level k, made within the for loop for the entry at level k that contains e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Having established that there is one recursive call for each entry of the file system, we return to the question of the overall computation time for the algorithm. It would be great if we could argue that we spend O(1) time in any single invocation of the function, but that is not the case. While there are a constant number of steps reflect in the call to os.path.getsize to compute the dish usage directly at that entry, when the entry is a directory, the body of the disk\\_usage function includes a for loop tha iterates over all entries that are contained within that directory. In the workst case, it is possible that one entry includes n - 1 others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- based on this reasoning, we could conclude that there are O(n) recursive calls, each of which runs in O(n) time, leading to an overall running time that is O(n^2). While this upper bound is technically true, it is not a tight upper bound. Remarkably, we can prove the stronger bound that the recursive algorithm for disk\\_usage completes in O(n) time! The weaker bound was pessimistic because  it assumed a worst-case number of entries for each directory. While it is possible that some directories contain a number of entries proportional to n, they cannot all contain that many. To prove the stronger claim, we choose to consider the overall number of iterations of the for loop across all recursive calls. We claim there are precisely n -1 such iteration of that loop overall. We base this claim on the fact that each iteration of that loop makes a recursive call to disk\\_usage, and yet we have already concluded that there are a total of n calls to disk\\_usage(including the original call). We therefore conclude that there are O(n) recursive calls, each of which uses O(1) time outside the loop, and that the overall number of operations due to the loop is O(n). Summing all of these bounds, the overall number of operations is O(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The arugment we have made is more advanced that with the ealier examples of recursion. The idea that we can sometimes get a tighter bound on a series of operations by considering the cumulative effect, rather than assuming that each achieves a worst case is a technique called amortization ; we will see a further example of such analysis in Section 5.3. Furthermore, a file system is an implicit example of a data structure known as a tree, and our disk usage algorithm is really a manifestation of a more general algorithm known as a tree traversal. Trees will be the focus of Chapter 8, and our argument about the O(n) running time of the disk usage algorithm will be generaliezed for tree traversals in Section 8.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://en.wikipedia.org/wiki/Amortized_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Recursion Run Amok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although recursion is a very powerful tool, it can easily be misused in various ways. In this section, we examine several problems in which a poorly implemented recursion causes drastic inefficiency, and we discuss some strategies for recognizing and avoid such pitfalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We begin by revisiting the element uniqueness problem, defined on page 135 of Section 3.3.3. We can use the following recursive formulation to determine if all n elements of a sequence are unique. As a base case, when n = 1, the elements are trivially unique. For n >= 2, the elements are unique if and only if the first n - 1 elements are unique, the last n - 1 items are unique, and the first and last elements are different(as that is the only pair that was not already checked as a subcase). A recursive implementation based on this idea is given in Code Fragment 4.6, named unique3 (to differentiate it from unique 1 and unque2  from Chapter 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique3(S, start, stop):\n",
    "    \"\"\"Return True if there are no duplicates elements in slice S[start:stop].\"\"\"\n",
    "    if stio - start <= 1: return True\n",
    "    elif not uniue(S, start, stop-1): return False\n",
    "    elif not uniqe(S, start+1, stop): return False\n",
    "    else: return S[start] != S[stop-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unfortunately, this is a terribly ineffeicient use of recursion. The nonrecursive part of each call uses O(1) time, so the overall running time will be proportional to the total number of recursive invocations. To analyze the problem, we let n denote the number of entries under consideration, that is, let n = stop - start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If n = 1, then the running time of unique3 is O(1), since there are no recursive calls for this case. In the general case, the important observation is that a single call to unique3 for a problem of size n may result in two recursive calls on problems of size n - 1. Those two calls with size n - 1 could in turn result in four calls (two each) with a range of size n - 2, and thus eight calls with size n - 3 and so on. Thus, in the worst case, the total number of function calls is given by the geometric summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 2 + 4 + ... + 2^(n-1),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which is equal to $2^{n}$ - 1 by Proposition 3.5. Thus, the running time of function unique3 is O(2^n). This is an incredibly inefficient function for solving the element uniqueness problem. Its inefficiency comes not from the fact that it uses recursion-it comes from the fact that it uses recusion poorly, which is something we address in Exercise C-4.11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** An Inefficient Recursion for Computing Fibonacci Numbers **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Section 1.8, we introduced a process for generating the Fibonacci numbers, which can be defined recursively as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F_{0} = 0 $$\n",
    "$$ F_{1} = 1 $$\n",
    "$$ F_{n} = F_{n-2} + F_{n-1} for n > 1. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ironically, a direct implementation based on this definition results in the function bad\\_fibonacci shown in Code Fragment 4.7, which computes the sequence of Fibonacci numbers by making two recursive calls in each non-base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bad_fibonacci(n):\n",
    "    \"\"\"Return the nth Fibonacci number.\"\"\"\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return bad_fibonacci(n-2) + bad_fibonacci(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Unfortunately, such a direct implementation of the Fibonacci formula results in a terribly inefficient function. Computing the $n^{th}$ Fibonacci number in this way requires an exponential number of calls to the function. Specifically, let $c_{n}$ denote the number of calls performed in the execution of bad\\_fibonacci(n). Then, we have the following values for the $c_{n}$'s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we follow the pattern forward, we see that the number of calls more than doubles for each two consecutive indices. That is, $c_{4}$ is more than twice $c_{2}$, $c_{5}$ is more than twice $c_{3}$, $c_{6}$ is more than twice $c_{4}$, and so on. Thus, $c_{n}$ > $c^{n/2}$, which means that bad\\_fibonacci(n) makes a number of calls that exponential in n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** An Efficient Recursion for Computing Fibonacci Numbers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We were tempted into using the bad recursion formulation because of the way the $n^{th}$ Fibonacci number, $F_{n}$, depends on the two previous values, $F_{n-2}$, $F_{n-1}$. But notice that after computing $F_{n-2}$, the call to conpute $F_{n-1}$ requires its own recursive call to compute $F_{n-2}$, as it does not have knowledge of the value of $F_{n-2}$ that was computed at the earlier level of recursion. That is duplicative work. Worse yet, both of those calls will need to (re)compute the value of $F_{n-3}$, as will the computation of $F_{n-1}$. This snowballing effect is what leads to the exponential running time of bad\\_recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can compute $F_{n}$ much more effieciently using a recursion in which each invocation makes only one recursive call. To do so, we need to redefine the expectaions of the function. Rather than having the function return a single value, which is the $n_{th}$ Fibonacci numbers ($F_{n}$, $F_{n-1}$), using the convention $F_{-1}$ = 0. Although it seems to be a greater burden to report two consecutive Fibonacci numbers instead of one, passing this extra information from one level of the recursion to the next makes it much easier to continue the process. (It allows us to avoid having to recompute the second value that was already known within the recursion.) An implementation based on this strategy is given in Code Fragment 4.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def good_fibonacci(n):\n",
    "    \"\"\"Return pair of Fibonacci numbers, F(n) and F(n-1).\"\"\"\n",
    "    if n <= 1:\n",
    "        return (n, 0)\n",
    "    else:\n",
    "        (a, b) = good_fibonacci(n-1)\n",
    "        return (a+b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, _ = good_fibonacci(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
