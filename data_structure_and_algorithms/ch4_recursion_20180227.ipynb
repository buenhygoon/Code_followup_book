{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursion is a technique by which a function makes one or more calls to itself during execution, or by which a data structure relies upon smaller instances of the very same type of structure in tis representation. There are many examples of recursion in art and nature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In computing recursion provides an elegant and powerful alternative for performing repetitive tasks. In fact, a few programming languages do not explicitly support looping constructs and instead rely directly on recursion to express repetition. Most modern programming languages support functional recursion using the identical mechanism that is used to support traditional forms of function calls. When one invovation of the function make a recursive call, that invocation is suspended until the recursive call completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The factorial function is a classic mathematical function that has a natural recursive definition.\n",
    "- An English ruler has a recursive pattern that is a simple example of a fractal structure.\n",
    "- Binary search is among the most important computer algorithms. It allows us to efficiently locate a desired value in a data set with upwards of billions of entries. \n",
    "- The file system for a computer has a recursive structure in which directories can be nested arbitrarily deeply within other directories. Recursive algorithms are widely used to explore and mange these file systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Illustrative Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.1.1 The Factorial Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To demonstrate the mechanics of recursion, we begin with a simple mathematical  example of computing the value of the factorial function. The factorial of a positive integer n, denoted n!, is defined as the product of the integers from 1 to n. If n = 0, then n! is defined as 1 by convention. More formally, for any integer n >= 0, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For exmaple, 5! = 5 \\* 4 \\* 3 \\* 2 * 1 = 120. The factorial function is important because it is known to equal the number of ways in which n distinct items can be arranged into a sequence, that is, the number of permutations of n items. For example, the three characters a, b and c can be arranged in 3! = 3 \\* 2 \\* 1 = 6 ways: abc, acb, bac, bca, cab and cba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a natural recursive definition for the factorial function. To see this, observe that 5! = 5 \\* (4 \\* 3 \\* 2 \\* 1) = 5 \\* 4!. More generally, for a positive integer n, we can define n! to be n \\* (n -1 )!. This recursive definition can be formalized as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This definition is typical of many recursive definitions. First, it contains one or more base cases, which are defined nonrecursively in terms of fixed quantities. In this case, n = 0 is the base case. It also contains one or more recursive cases, which are defined by appealing to the definition of the function beign defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A Recursive Implementation of the Factorial Function **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursion is not just a mathmatical notation: we can use recursion to design a Python implementation of a factorial function, as shown in Code Fragment 4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function does not use any explicit loops. Repetition is provided by the repeated recursive invocations of the function. There is no circularity in this definition, because each time the function is invoked, its argument is smaller by one, and when a base case is reached, no further recursive calls are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We illustrate the execution of a recursive function using a **recursive trace**. Each entry of the trace corresponds to a recursive call. Each new recursive function call is indicated by a downward arrow to a new invocation. When the function returns, an arrow showing this return is drawn and the return value may be indicated alongside this arrow. An example of such a trace for the factorial function is shown in Figure 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A recursion trace closely mirrors the programming language's execution of the recursion. In Python, each time a function is called, a structure known as an activation record or frame is created to store information about the progress of that invocation of the function. This activation record includes a namespace for storign the function call's parameters and local variables, and information about which command in the body of the function is currently executing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the execution of a function leads to a nested function call, the execution of the former call is suspended and its activation record stores the place in the source code at which the flow of control should continue upon return of the nested call. This process is used both in the standard case of function calling a different function, or in the recursive case in which a function invokes itself. The key point is that there is a different activation record for each active call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Drawing an English Ruler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the case of computing a factorial, there is no compelling reason for preferring recursion over a direct iteration with a loop. As a major complew example of the use of recursion, consider how to draw the markings of a typical English ruler. For each inch, we place a tick with a numeric label. We denote the length of the tick designating a whole inch as the major tick length. Between the marks for whole inches, the ruler contains a series of minor ticks, placed at intervals of 1/2 inch, 1/4 inch, and so on. As the size of the interval decreases by half, the tick length decreases by one/. Figure 4.2 demonstrates several such rulers with varying major tick lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A Recursive Approach to Ruler Drawing **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The English ruler pattern is a simple example of a fractal , that is, a shape that has a self-recursive structure at various levels of magnification. Consider the rule with major tick length 5 shown in Figure 4.2(b). Ignoring the lines containing 0 and 1, let us consider how to draw the sequence of tick lying between these lines. The central tick has length 4. Observe that the two patterns of ticks above and below this central tick are identical, and each has a central tick of length 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In general, an interval with a central tick length L >= 1 is composed of :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- An interval with a central tick length L-1\n",
    "- A single tick of length L\n",
    "- An interval with a central tick length L-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Although it is possible to draw such a ruler using an iterative process, the task is considerably easier to accomplish with recursion. Our implementation consists of three functions, as shown in Code Fragment 4.2. The main function, draw\\_ruler, manages the construction of the entire ruler. Its arguments specify the total number of inches in the ruler and the major tick length. The utility function, draw\\_line, draws a single tich with a specified number of dashes. \n",
    "- The interesting work is done by the recursive draw\\_interval function. This function draws the sequence of minor ticks within some interval, based upon the length of the interval's central tick. We rely on the intuition shown at the top of this last steps are performed by resursively calling draw\\_interval(L - 1). The middle step is performed by calling the function draw\\_line(L)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_line(tick_length, tick_label=''):\n",
    "    \"\"\"Draw one line with given tick length (followed by optional label).\"\"\"\n",
    "    line = '-' * tick_length\n",
    "    if tick_label:\n",
    "        line += ' ' + tick_label\n",
    "    print(line)\n",
    "    \n",
    "def draw_interval(center_length):\n",
    "    \"\"\"Draw tick interval based upon a central tick length.\"\"\"\n",
    "    if center_length > 0:\n",
    "        draw_interval(center_length - 1)\n",
    "        draw_line(center_length)\n",
    "        draw_interval(center_length - 1)\n",
    "        \n",
    "def draw_ruler(num_inches, major_length):\n",
    "    \"\"\"Draw Enlgish ruler with given number of inches, major tick length.\"\"\"\n",
    "    draw_line(major_length, '0')\n",
    "    for j in range(1, 1 + num_inches):\n",
    "        draw_interval(major_length - 1)\n",
    "        draw_line(major_length, str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Illustrating Ruler Drawing Using a Recursion Trace **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The execution of the recursive draw\\_interval function can be visualized using a recursion trace. The trace for draw\\_interval is more complicated than in the factorial example, however, because each instance makes two recursive calls. To illustrate this, we will show the recursion trace in a form that is reminiscent of an outline for a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Binary Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we describe a classic recursive algorithm, binary search, that is used to efficiently locate a target value within a sorted sequence of n elements. This is among the most inportant of computer algorithms, and it is the reason that we so often store data in sorted order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the sequence is unsorted, the standard approach to search for a target value is to use a loop to examine every element, until either finding the target or exhausting the data set. This is known as the sequential search algorithm. This algorithm runs in O(n) time since every element is inspected in the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the sequence is sorted and indexable, there is a much more efficient algorithm. For any index j, we know that all the values stored at indices 0, ... , j - 1 are less than or equal to the value at index j, and all the values stored at indices j + 1, ..., n - 1 are greater than or equal to that at index j. This observation allows us to quickly \"home in\" on a search target using a variant of the children's game \"high-low\". We call an element of the sequence a candidate if, at the current stage of the search, we cannot rule out that this item matches the target. The algorithm maintains two parameters, low and high, such that all the candidate entries have index at least low and at most high. Initailly, low = 0 and high = n - 1. We then compare the target value to the median candidate, that is , the item data[mid] with index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We consider three cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the target equals data[mid], then we have found the item we are looking for, and the search terminates successfully. \n",
    "- If target < data[mid], then we recur on the first half of the sequence, that  is, on the interval of indices from low to mid -1.\n",
    "- If target > data[mid], then we recur on the second half of the sequence, that is, on the interval of indices from mid + 1 to high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An unsuccessful search occurs if low > high, as the interval [low, high] is empty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This algorithm is known as binary search. We give a Python implementation in Code Fragment 4.3, and an illustration of the execution of the algorithm in Figure 4.5. Whereas sequential search runs in O(n) time, the more efficient binary search runs in O(log n) time. This is a significant improvement, given that if n is one billion, log n is only 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_search(data, target, low, high):\n",
    "    \"\"\"Return True if target is found in indicated portion of a Python list.\n",
    "    \n",
    "    The search only considers the portion from data[low] to data[high] inclusive.\n",
    "    \"\"\"\n",
    "    if low > high:\n",
    "        return False\n",
    "    else:\n",
    "        mid = (low + high) // 2\n",
    "        if target == data[mid]:\n",
    "            return True\n",
    "        elif target < data[mid]:\n",
    "            # recur on the portion left of the middle\n",
    "            return binary_search(data, target, low, mid - 1)\n",
    "        else:\n",
    "            # recur on the portion right of the middle\n",
    "            return binary_search(data, target, mid + 1, high)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 File Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modern operating systems define file-system directories (which are also sometimes called \"folders\") in a recursive way. Namely, a file system consists of a top-level directory, and the contents of this directory consists of files and other directories, which in turn can contain files and other directories, and so on. The operating system allows directories to be nested arbitrarily deep (as long as there is enough space in memory), although there must necessarily be some base directories that contain only files, not further subdirectories. A representation of a portion of such file system is given in Figure 4.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Given the recursive nature of the file-system representation, it should not come as a surprise that many common behaviors of an operating system, such as copying a directory or deleting a diretory, are implemented with recursive algorithms.** In this section, we consider one such algorithm: computing the total isk usage for all files and directories nested within a particular directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For illustration, Figure 4.7 portrays the disk space being used by all entries in our sample file system. We differentiate between the immediate disk space used by each entry and the cumulative disk space space used by that entry and all nested features. For example, the cs016 diretory uses only 2K of immediate space, but a total of 249K of cumulative space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cumulative disk spcae for an entry can be computed with a simple recursive algorithm. It is equal to the immediate disk space used by the entry plus the sum of the cumulative disk space usage of any entries that are stored directly within the entry. For example, cumulative disk space for cs016 is 249K because it uses 2K itself, 8K cumulatively in grades, 10K cumulatively homeworks, and 229K cumultively in programs. Pseudo-code for this algorithm is given in Code-Fragment 4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm DiskUsage(path):\n",
    "  Input: A string designating a path to a file-system entry\n",
    "  Output: The cumulative disk space used by that entry and any nested entries \n",
    "  total = size(path)\n",
    "  if path represents a directory then\n",
    "    for each child entry stored within directory path do\n",
    "      total = total + DistUsage(child)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Python's os Module **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- To provide a Python implementation of a recursive algorithm for computing disk usage, we rely on Python's os module, which provides robust tools for interacting with the operating system during the execution of a program. This is an extensive library, but we will only need the following four functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- os.path.getsize(path) : Return the immediate disk usage (measured in bytes) for the file or directory that is identified by the string path(e.g., /user/rt/courses).\n",
    "\n",
    "- os.path.isdir(path) : Return True if entry designated by string path is a directory; False otherwise.\n",
    "\n",
    "- os.listdir(path) : Return a list of string that are the names of all entries within a directory designated by string path. IN our sample file system, if the parameter is /user/rt//courses, this returns the list['cs016', 'cs252'].\n",
    "\n",
    "- os.path.join(path, filename) : Compose the path string and filename string using an appropriate operating system separator between the two(e.g., the / character for a Unix/Linux syste, and the \\ character for Windows). Return the string that represents the full path to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Python Implementation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def disk_usage(path):\n",
    "    \"\"\"Return the number of bytes used by a file/folder and any descendents.\"\"\"\n",
    "    total = os.path.getsize(path)\n",
    "    if os.path.isdir(path):\n",
    "        for filename in os.listdir(path):\n",
    "            childpath = os.path.join(path, filename)\n",
    "            total += disk_usage(childpath)\n",
    "    \n",
    "    print('{0:<7}'.format(total), path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26405   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch1_python_primer-checkpoint.ipynb\n",
      "49455   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch2_oop_20180223-checkpoint.ipynb\n",
      "33750   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch3_alorithm_analysis_20180226-checkpoint.ipynb\n",
      "18047   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints/ch4_recursion_20180227-checkpoint.ipynb\n",
      "131753  /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/.ipynb_checkpoints\n",
      "56428   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/bigoh_function.png\n",
      "26405   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch1_python_primer.ipynb\n",
      "49455   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch2_oop_20180223.ipynb\n",
      "33750   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch3_alorithm_analysis_20180226.ipynb\n",
      "21334   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/ch4_recursion_20180227.ipynb\n",
      "27712   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/classes_of_functions.png\n",
      "43795   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/function_parameter.png\n",
      "65677   /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms/inheritance.png\n",
      "460405  /home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "460405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_usage('/home/dockeruser/hostname/workspace/git/kaden/code_followup_book/data_structure_and_algorithms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recursion Trace **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To produce a different form of a recursion trace, we have included an extraneous print statement within our Python implementation. The precise format of that output intentionally mirros output that is produced by a classic Unix/Linux utility named du(for \"disk usage\"). It reports the amount of disk space used by a directory and all contents nested within, and can produce a verbose report, as given in Figure 4.8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our implementation of the disk\\_usage function produces an identical result, when executed on the sample file system portrayed in Figure 4.7. During the execution of the algorithm, exactly one recursive call is made for each entry in the portion of the file system that is considered. Because the print statement is made just before returning from a recursive call, the output shown in Figure 4.8 reflects the order in which the recursive calls are completed. In particular, we begin and end a recursive call for each entry that is nested below another entry, computing the nested cumulative disk space before we can compute and report the cumulative disk space for the containing entry. For example, we do not know the cumulative total for entry /user/rt/courses/cs016 until after the recursive calls regarding contained entries grades, homeworks, and programs complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Analyzing Recursive Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Chapter 3, we introduced mathematical techniques for analyzing the efficiency of an algorithm, based upon an estimate of the number of primitive operations that are executed by the algorithm. We use notations such as big-Oh to summarize the relationship between the number of operations and the input size for a problem. In this section, we demonstrate how to perform this type of running-time analysis to recursive algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a recursive algorithm, we will account for each operation that is performed based upon the particular activation of the function that manages the flow of control at the time it is executed. Stated another way, for each invocation of the function, we only account for the number of operations that are performed within the body of that activation. We can then account for the overall number of operations that are executed as part of the recursive algorithm by taking the sum, over all activations, of the number of operations that take place during each individual activation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- To demonstrate this style of analysis, we revisit the four recursive algorithms presented in Sections 4.1.1 through 4.1.4: factorial computation, drawing an English ruler, binary search, and computation of the cumulative size of a file system. In general, we may rely on the intuition afforded by a recursion trace in recognizing how many recursive activations occur, and how the parameterization of each activation can be used to estimate the number of primitive operations that occur within the body of that activation. However, each of these recursive algorithms has a unique structure and form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Computing Factorials **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is relatively easy to analyze the efficiency of our function for computing factorials, as described in Section 4.1.1. A sample recursion trace for our factorial function was given in Figure 4.1. To compute factorial(n), we see that there are a total of n + 1 activations, as the parameter decreases from n in the first call , to n - 1in the second call, and so on, until reaching the base with parameter 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is also clear, given as examination of the function body in Code Fragment 4.1, that each individual activation of factorial executes a constant number of operations. Therefore, we conclude that the overall number of operations for computing factorial(n) is O(n), as there are n + 1 activations, each of which accounts for O(1) operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Drawing an English Ruler **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In analyzing the English ruler application from Section 4.1.2, we consider the fundamental question of how many total lines of output are generated by an initial call to draw\\_interval(c), where c denotes the center length. This is a reasonable benchmark for the overall efficiency of the algorithm as each line of output is based upon a call to the draw\\_line utility, and each recursive call to draw\\_interval with nonzero parameter makes exactly one direct call to draw\\_line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some intuition may be gained by examining the source code and the recursion trace. We know that a call to draw\\_interval(c) for c>0 spawns two calls to draw\\_interval(c-1) and a single call to draw\\_line. We will rely on this intuition to prove the following claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justification**: We provide a formal proof of this claim by induction. In fact, induction is a natural mathematical technique for proving the correctness and efficiency of a recursive process. In the case of the ruler, we note that an application of draw\\_interval(0) generates no output, and that $2^0$ - 1 = 1 - 1 = 0. This serves as a base case for our claim. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performing a Binary Search **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considering the running time of the binary search algorithm, as presented in Section 4.1.3, we observe that a constant number of primitive operations are executed at each resursive call of method of a binary search. Hence, the running time is proportional to the number of recursive calls performed. We will show that at most [log n] + 1 recursive calls are made during a binary search of a sequence having n elements, leading to the following claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Justification: To prove this claim, a crucial fact is that with each recursive call the number of candidate entries still to be searched is given by the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ high - low + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moreover, the number of remaining candidates is reduced by at least one half with each recursive call. Specifically, from the definition of mid, the number of remaining candidates is either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initially, the number of candidates is n; after the first call in a binary search, it is at most n/2; after the second call, it is at most n/4; nad so on. In general, after the jth call in a binary search, the number of candidate entries remaining is at most n/2j. IN the worst case(an unsuccessful search), the recursive calls stop when there are no more candidate entries. Hence, the maximum number of recursive calls performed, is the smallest integer r such that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\dfrac{n}{2^r} < 1. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In other words (recalling that we omit a logrithm's base when it is 2), r > logn. Thus, we have "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ r = [\\log{n}] + 1, $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which implies that binary search runs in O(log n) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Computing Disk Space Usage **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our final recursive algorithm from Section 4.1 was that for computing the overall disk space usage in a specified portion of a file system. To characterize the \"problem size\" for our analysis, we let n denote the number of file-system entries in the portion of the file system that is considered. (For example, the file system portrayed in Figure 4.6 has n = 19 entries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To characterize the cumulative time spent for an initial call to the disk\\_usage function, we must analyze the total number of recursive invocations that are made, as well as the number of operations that are executed within those invocations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We begin by showing that there are precisely n recursive invocations of the function, in particular, one for each entry in the relevant portion of the file system. Intuitively, this is because a call to disk\\_usage for a particular entry e of the file system is only made from within the for loop of Code Fragment 4.5 when processing the entry for the unique directory that contains e, and that entry will only be explored once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To formalize this argument, we can define the nesting level of each entry such that the entry on which we begin has nesting level 0, entries stored directly within it have nesting level 1, entries stored within those entries have nesting level 2, and so on. We can prove by induction that there is exactly one recursive invocation of disk\\_usage upon each entry at nesting level k. As a base case, when k = 0, the only recursive invocation made is the initial one. As the inductive step, once we know there is exactly one recursive invocation for each entry at nesting level k, we can claim that there is exactly one invocation for each entry e at nesting level k, made within the for loop for the entry at level k that contains e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Having established that there is one recursive call for each entry of the file system, we return to the question of the overall computation time for the algorithm. It would be great if we could argue that we spend O(1) time in any single invocation of the function, but that is not the case. While there are a constant number of steps reflect in the call to os.path.getsize to compute the dish usage directly at that entry, when the entry is a directory, the body of the disk\\_usage function includes a for loop tha iterates over all entries that are contained within that directory. In the workst case, it is possible that one entry includes n - 1 others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- based on this reasoning, we could conclude that there are O(n) recursive calls, each of which runs in O(n) time, leading to an overall running time that is O(n^2). While this upper bound is technically true, it is not a tight upper bound. Remarkably, we can prove the stronger bound that the recursive algorithm for disk\\_usage completes in O(n) time! The weaker bound was pessimistic because  it assumed a worst-case number of entries for each directory. While it is possible that some directories contain a number of entries proportional to n, they cannot all contain that many. To prove the stronger claim, we choose to consider the overall number of iterations of the for loop across all recursive calls. We claim there are precisely n -1 such iteration of that loop overall. We base this claim on the fact that each iteration of that loop makes a recursive call to disk\\_usage, and yet we have already concluded that there are a total of n calls to disk\\_usage(including the original call). We therefore conclude that there are O(n) recursive calls, each of which uses O(1) time outside the loop, and that the overall number of operations due to the loop is O(n). Summing all of these bounds, the overall number of operations is O(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The arugment we have made is more advanced that with the ealier examples of recursion. The idea that we can sometimes get a tighter bound on a series of operations by considering the cumulative effect, rather than assuming that each achieves a worst case is a technique called amortization ; we will see a further example of such analysis in Section 5.3. Furthermore, a file system is an implicit example of a data structure known as a tree, and our disk usage algorithm is really a manifestation of a more general algorithm known as a tree traversal. Trees will be the focus of Chapter 8, and our argument about the O(n) running time of the disk usage algorithm will be generaliezed for tree traversals in Section 8.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://en.wikipedia.org/wiki/Amortized_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Recursion Run Amok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although recursion is a very powerful tool, it can easily be misused in various ways. In this section, we examine several problems in which a poorly implemented recursion causes drastic inefficiency, and we discuss some strategies for recognizing and avoid such pitfalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We begin by revisiting the element uniqueness problem, defined on page 135 of Section 3.3.3. We can use the following recursive formulation to determine if all n elements of a sequence are unique. As a base case, when n = 1, the elements are trivially unique. For n >= 2, the elements are unique if and only if the first n - 1 elements are unique, the last n - 1 items are unique, and the first and last elements are different(as that is the only pair that was not already checked as a subcase). A recursive implementation based on this idea is given in Code Fragment 4.6, named unique3 (to differentiate it from unique 1 and unque2  from Chapter 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique3(S, start, stop):\n",
    "    \"\"\"Return True if there are no duplicates elements in slice S[start:stop].\"\"\"\n",
    "    if stio - start <= 1: return True\n",
    "    elif not uniue(S, start, stop-1): return False\n",
    "    elif not uniqe(S, start+1, stop): return False\n",
    "    else: return S[start] != S[stop-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unfortunately, this is a terribly ineffeicient use of recursion. The nonrecursive part of each call uses O(1) time, so the overall running time will be proportional to the total number of recursive invocations. To analyze the problem, we let n denote the number of entries under consideration, that is, let n = stop - start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If n = 1, then the running time of unique3 is O(1), since there are no recursive calls for this case. In the general case, the important observation is that a single call to unique3 for a problem of size n may result in two recursive calls on problems of size n - 1. Those two calls with size n - 1 could in turn result in four calls (two each) with a range of size n - 2, and thus eight calls with size n - 3 and so on. Thus, in the worst case, the total number of function calls is given by the geometric summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 2 + 4 + ... + 2^(n-1),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which is equal to $2^{n}$ - 1 by Proposition 3.5. Thus, the running time of function unique3 is O(2^n). This is an incredibly inefficient function for solving the element uniqueness problem. Its inefficiency comes not from the fact that it uses recursion-it comes from the fact that it uses recusion poorly, which is something we address in Exercise C-4.11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** An Inefficient Recursion for Computing Fibonacci Numbers **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Section 1.8, we introduced a process for generating the Fibonacci numbers, which can be defined recursively as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F_{0} = 0 $$\n",
    "$$ F_{1} = 1 $$\n",
    "$$ F_{n} = F_{n-2} + F_{n-1} for n > 1. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ironically, a direct implementation based on this definition results in the function bad\\_fibonacci shown in Code Fragment 4.7, which computes the sequence of Fibonacci numbers by making two recursive calls in each non-base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bad_fibonacci(n):\n",
    "    \"\"\"Return the nth Fibonacci number.\"\"\"\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return bad_fibonacci(n-2) + bad_fibonacci(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Unfortunately, such a direct implementation of the Fibonacci formula results in a terribly inefficient function. Computing the $n^{th}$ Fibonacci number in this way requires an exponential number of calls to the function. Specifically, let $c_{n}$ denote the number of calls performed in the execution of bad\\_fibonacci(n). Then, we have the following values for the $c_{n}$'s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we follow the pattern forward, we see that the number of calls more than doubles for each two consecutive indices. That is, $c_{4}$ is more than twice $c_{2}$, $c_{5}$ is more than twice $c_{3}$, $c_{6}$ is more than twice $c_{4}$, and so on. Thus, $c_{n}$ > $c^{n/2}$, which means that bad\\_fibonacci(n) makes a number of calls that exponential in n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** An Efficient Recursion for Computing Fibonacci Numbers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We were tempted into using the bad recursion formulation because of the way the $n^{th}$ Fibonacci number, $F_{n}$, depends on the two previous values, $F_{n-2}$, $F_{n-1}$. But notice that after computing $F_{n-2}$, the call to conpute $F_{n-1}$ requires its own recursive call to compute $F_{n-2}$, as it does not have knowledge of the value of $F_{n-2}$ that was computed at the earlier level of recursion. That is duplicative work. Worse yet, both of those calls will need to (re)compute the value of $F_{n-3}$, as will the computation of $F_{n-1}$. This snowballing effect is what leads to the exponential running time of bad\\_recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can compute $F_{n}$ much more effieciently using a recursion in which each invocation makes only one recursive call. To do so, we need to redefine the expectaions of the function. Rather than having the function return a single value, which is the $n_{th}$ Fibonacci numbers ($F_{n}$, $F_{n-1}$), using the convention $F_{-1}$ = 0. Although it seems to be a greater burden to report two consecutive Fibonacci numbers instead of one, passing this extra information from one level of the recursion to the next makes it much easier to continue the process. (It allows us to avoid having to recompute the second value that was already known within the recursion.) An implementation based on this strategy is given in Code Fragment 4.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def good_fibonacci(n):\n",
    "    \"\"\"Return pair of Fibonacci numbers, F(n) and F(n-1).\"\"\"\n",
    "    if n <= 1:\n",
    "        return (n, 0)\n",
    "    else:\n",
    "        (a, b) = good_fibonacci(n-1)\n",
    "        return (a+b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, _ = good_fibonacci(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- In terms of effieciency, the difference between the bad recursion and the good recursion for this problem is like night and day. The bad\\_fibonacci function uses exponential time. We claim that the execution of function good\\_fibonacci(n) takes O(n) time. Each recursive call to good\\_fibonacci decreases the argument n by 1; therefore, a recursion trace includes a series of n function calls. Because the nonrecursive work for each call uses constant time, the overall computation executes in O(n) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Maximum Recursive Depth in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another danger in the misuse of recursion is known as infinite recursion. If each recursive call makes another recursive call, without ever reaching a base case, then we have an infinite series of such calls. This is a fatal error. An infinite recursion can quickly swamp computing resources, not only due to rapid use of the CPU, but because each successive call creates an activation record requiring additional memory. A blatant example of an ill-formed recursion is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    return fib(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- However, there are far more subtle errors that can lead to an infinite recursion. Revisiting our implementation of binary search in Code Fragment 4.3, in the final case we makes a resursive call on the right portion of the sequence, in particular going from index mid + 1 to high. Had that line instead been written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return binary_search(data, target, mid, high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this could result in an infinite recursion. In particular, when searching a range of two elements, it becomes possible to make a recursive call on the identical range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A programmer should ensure that each recursive call is in some way progressing toward a base case (for example, by having a parameter value that decreases with each call). However, to combat against infinite recursions, the designers of Python made an intentional decision to limit the overall number of function activations that can be simultaneously active. The precise value of this limit depends upon the Python distribution, but a typical default value is 1000. If this limit is reached, the Python interpreter raises a RuntimeError with a message, maximum recursion depth exeeded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For many legitimate applications of recursion, a limit of 1000 nested function calls suffices. For example, our binary\\_search function has O(logn) recursive depth, and so for the  default recursive limit to be reached, there would need to be $2^{1000}$ elements (far, far more than the estimated number of atoms in the universe). However, in the next section we discuss several algorithms that have recursive depth proportional to n. Python's artificial limit on the recursive depth could disrupt such otherwise legitimate computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fortunately, the Python interpreter can be dynamically reconfigured to change the default recursive limit. This is done through use of a module named sys, which supports a getrecursionlimit function and a setrecursionlimit. Sample usage of those functions is demonstrated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "old = sys.getrecursionlimit() # perhaps 1000 is typical  \n",
    "sys.setrecursionlimit(1000000) # change to allow 1 million nested calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Further Examples of Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the remainder of this chapter, we provide additional examples of the use of resursion. We organize our presentation by considering the maximum number of recursive calls that may be started from within the body of a single activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If a recursive call start at most one other, we call this a linear recursion.\n",
    "- If a recursive call may start two others, we call this a binary recursion.\n",
    "- If a recursive call may start three or more others, this is multiple recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Linear Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If a recursive function is designed so that each invocation of the body makes at most one new recursive call, this is known as linear resursion. Of the recursions we have seen so far, the implementation of the factorial function and the good\\_fibonacci function are clear examples of linear recursion. More interestingly, the binary search algorithm is also an example of linear recursion, despite the \"binary\" terminology in the name. The code for binary search includes a case analysis with two branches that lead to recursive calls, but only one of those calls can be reached during a particular execution of the body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A consequence of the definition of linear recursion is that any recursion trace will appear as a single sequence of calls, as we originally portrayed for the factorial function in Figure 4.1 of Section 4.1.1. Note that the linear recursion terminology reflects the structure of the recursion trace, not the asymptotic analysis of the running time; for example, we have seen that binary search runs in O(log n) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summing the elements of a Sequence Recursively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear resursion can be a useful tool for processing a data sequence, such as a Python list. Suppose, for example, that we want to compute the sum of a sequence, S, of n integers. We can solve this summation problem using linear recusion by observing that the sum of all n integers in S is trivially 0, if n = 0, and otherwise that it is the sum of the first n - 1 integers in S plus the last element in S. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A recursive algorithm for computing the sum of a sequence of numbers based on the intuition is implemented in Code Fragment 4.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_sum(S, n):\n",
    "    \"\"\"Return the sum of the first n numbers of sequence S.\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return linear_sum(S, n-1) + S[n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A recursion trace of the linear\\_sum function for a small example is given in Figure 4.10. For an input of size n, the linear\\_sum algorithm makes n + 1 function calls. Hence, it will take O(n) time, because it spends a constant amount of time performing the nonrecursive part of each call. Moreover, we can also see that the memory space used by the algorithm is also O(n), as we use a constant amount of memory space for each of the n + 1 activation records in the trace at the time we make the final recursive call (with n = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reversing a Sequence with Recursion **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, let us consider the problem of reversing the n elements of a sequence, S, so that the first element becomes the last, the second element becomes second to the last, and so on. We can solve this problem using linear recursion, by observing that the reversal of a sequence can be achieved by swapping the first and last elements and then recursively reversing the remaining elements. We present an implementation of this algorithm in Code Fragment 4.10, using the convention that the first time we call this algorithm we do so as reverse(S, 0, len(S))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse(S, start, stop):\n",
    "    \"\"\"Reverse elements in implicit slice S[start:stop].\"\"\"\n",
    "    if start < stop - 1:\n",
    "        S[start], S[stop-1] = S[stop-1], S[start]\n",
    "        reverse(S, start+1, stop-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that there are two implicit base case scenarios : When start == stop, the implicit range is empty, and when start == stop - 1, the implicit range has only one element. In either of these cases, there is no need for action, as a sequence with zero elements or one element is trivially equal to its reversal. When otherwise invoking recursion, we are guaranteed to make progress towards a base case, as the difference, stop-start, decreases by two with each call. If n is even, we will eventually reach the start == stop case, and if n is odd, we will eventually reach the start == stop - 1 case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above argument implies that the recursive algorithm of Code Fragment 4.10 is guaranteed to terminate after a total of 1 + [n/2] recursive calls. Since each call involves a constant amount of work, the entire process runs in O(n) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Recursive Algorithms for Computing Powers **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As another interesting example of the use of linear recursion, we consider the problem of raising a number x to an arbitrary nonnegative integer, n. That is, we wish to compute the power function, defined as power(x,n) = $x^{n}$. (We use the name \"power\" for this discussion, to differentiate from the built-in function pow that provides such functionality.) We will consider two different recursive formulations for the problem that lead to algorithms with very different performance. \n",
    "- A trivial reursive definition follows from the fact that $x^{n} = x * x^{n-1}$ for n > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This definition leads to a recursive algorithm shown in Code Fragment 4.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power(x, n):\n",
    "    \"\"\"Compute the value x**n for integer n.\"\"\"\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return x * power(x, n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A recursive call to this version of power(x, n) runs in O(n) time. Its recursion trace has structure very similar to that of the factorial function from Figure 4.1, with the parameter decreasing by one with each call, and constant work performed at each of n + 1 levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- However, there is a much faster way to comptute the power function using an alternative definition that employs a squaring technique. Let k = [n / 2] denote the floor of the division (expressed as n // 2 in Python). We consider the expression $ (x^{k})^{2}$. When n is even, [n / 2] = n / 2 and therefore $ (x^{k})^{2} = (x^{n/2})^{2} = x^{n}$. When n is odd, $ [\\dfrac{n}{2}] = \\dfrac{n-1}{2} $ and $ (x^{k})^{2} = x^{n-1}$, and therefore $x^{n} = x*(x^{k})^{2}$, just as $ 2^{13} = 2*2^{6}*2^{6}$. This analysis leads to the following recursive definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we were to implement this recursion making two recursive calls to compute power(x, [n/2])\\*power(x, [n/2]), a trace of the recursion would demonstrate O(n) calss. We can perform significantly fewer operations by computing power(x, [x/2]) as a partial result, and then multiplying it by itself. An implementation based on this recursive definition is given is Code Fragment 4.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power(x, n):\n",
    "    \"\"\"Compute the value x**n for integer n.\"\"\"\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        partial = power(x, n//2)\n",
    "        result = partial * partial\n",
    "        if n % 2 == 1:\n",
    "            result *= x \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To illustrate the execution of our improved algorithm, Figure 4.12 provides a recursion trace of the computation power(2, 13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![main](powerrecursion.png \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To analyze the running time of the revised algorithm, we observe that the exponent in each recursive call of function power(x, n) is at most half of the processing exponent. As we saw with the analysis of binary search, the number of times that we can divide n in half before getting to one or less is O(log n). Therefore, our new formulation of the power function results in O(log n) recursive calls. Each individual activation of the function uses O(1) operations (excluding the recursive calls), and so the total number of operations for computing power(x,n)is O(log n). This is a significant improvement over the original O(n)-time algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The improved version also provides significant saving in reducing the memory usage. The first version has a recursive depth of O(n), and therefore O(n) activation records are simultaneous stored in memory. Because the recursive depth of the improved version is O(log n), its memory usages is O(log n) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Binary Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a function makes two recursive calls, we say that it uses binary recursion. We have already seen several examples of binary recursion, most notably when drawing the English ruler, or in the bad\\_fibonacci function. As another application of binary recursion, let us revisit the problem of summing the n elements of a sequence, S, of numbers. Computing the sum of one or zero elements is trivial. With two or more elements, we can recursively compute the sum of the first half, and the sum of the second half, and add these sums together. Our implementation of such an algorithm, in Code Fragment 4.13, is initially invoked as binary\\_sum(A, 0, len(A))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_sum(S, start, stop):\n",
    "    \"\"\"Return the sum of the numbers in implicit slice S[start:stop].\"\"\"\n",
    "    if start >= stop:\n",
    "        return 0\n",
    "    elif start == stop-1:\n",
    "        return S[start]\n",
    "    else:\n",
    "        mid = (start + stop) // 2\n",
    "        return binary_sum(S, start, mid) + binary_sum(S, mid, stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To analyze algorithm binary\\_sum, we consider, for simplicity, the case where n is a power of two. Figure 4.13 shows the recursion trace of an execution of binary\\_sum(0, 8). We label each bow with the values of parameters start:stop for that call. The size of the range is divided in half at each recursive call, and so the depth of the recursion is 1 + $ \\log_{2}n$. Therefore, binary\\_sum uses O(log n) amount of additional space, which is a big improvement over the O(n) space used by the linear\\_sum function of Code Fragment 4.9. However, the running time of binary\\_sum is O(n), as there are 2n - 1 function calls, each requiring constant time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Multiple Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generalizing from binary recursion, we define multiple recursion as a process in which a function may make more than two recursive calls. Our recursion for analyzing the disk space usage of a file system is an example of multiple recursion, because the number of recursive calls made during one invocation was equal to the number of entries within a given directory of the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
