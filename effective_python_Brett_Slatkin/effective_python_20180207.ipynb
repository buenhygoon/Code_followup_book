{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I40 : Consider Coroutines to Run Many Functions Concurrently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More about : https://www.geeksforgeeks.org/coroutine-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Threads give Python programmers a way to run multiple functions seemingly at the same time. But there are three big problems with threads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- They require special tools to coodinate with each other safely. This makes code that uses threads harder to reason about than procedural, single-treaded code. This complexity makes threaded code more difficult to extend and maintain over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thread requirea a lot of memory, about 8 MB per executing thread. On many computers, that amount of memory doesn't matter for a dozen threads or so. But what if you want your program to run tens of thousands of functions \"simultaneously\"? These functions may correspond to user requests to a server pixels oon a screen, particles in a simulation, etc. Running a thread per unique activity just won't work.\n",
    "- Theads are costly to start. If you want to constantly be creating new concurrent functions and finishign them, the overhead of using threads becomes large and slows everything down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python can work around all these issues with *coroutines*. Coroutines let you have many seemingly sumultaneous functions in your Python programs. They're implemented as an extension to generators. The cost of starting a generator coroutine is a function call. Once active, they each use less that 1KB of memory until they're exhausted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coroutines work by enabling the code consuing a generator to send a value back into the generator function after each yield expression. The generator function receives the value passed to the send function as the result of the corresponding yield expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received: First\n",
      "Received: Second\n",
      "Received: yield\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def my_coroutine():\n",
    "    while True:\n",
    "        received = yield\n",
    "#         value = yield received\n",
    "        print('Received:', received)\n",
    "        \n",
    "it = my_coroutine()\n",
    "next(it)\n",
    "it.send('First')\n",
    "it.send('Second')\n",
    "print(it.send('yield'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The initail call to next is required to prepare the generator for receiving the first send by advancing it to the first yield expression. Together, yield and send provide generators with a standard way to vary their next yielded value in response to external input.\n",
    "\n",
    "- For example, say you want to implement a generator coroutine that yields the minimum value it's been sent so far. Here, the bare yield prepares the coroutine with the initial minumum value sent in from the outside. Then the generator repeatedly yields the new munimum in exchange for the next value to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "4\n",
      "4\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def minimize():\n",
    "    current = yield\n",
    "    while True:\n",
    "        value = yield current\n",
    "        current = min(value, current)\n",
    "        \n",
    "it = minimize()\n",
    "next(it)\n",
    "print(it.send(10))\n",
    "print(it.send(4))\n",
    "print(it.send(22))\n",
    "print(it.send(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generator function will seemingly run forever, making forward progress with each new call to send. Like threads, coroutines are independent functions that can consume inputs from their environment and produce resulting outputs. The difference is that coroutines pause at each yield expression in the generator function and resume after each call to send from the outside. This is the magical mechanism of coroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching prefix:Dear\n",
      "Dear Atul\n"
     ]
    }
   ],
   "source": [
    "def print_name(prefix):\n",
    "    print(\"Searching prefix:{}\".format(prefix))\n",
    "    while True:\n",
    "        name = (yield)\n",
    "        if prefix in name:\n",
    "            print(name)\n",
    " \n",
    "# calling coroutine, nothing will happen\n",
    "corou = print_name(\"Dear\")\n",
    " \n",
    "# This will start execution of coroutine and \n",
    "# Prints first line \"Searchig prefix...\"\n",
    "# and advance execution to the first yield expression\n",
    "corou.__next__()\n",
    " \n",
    "# sending inputs\n",
    "corou.send(\"Atul\")\n",
    "corou.send(\"Dear Atul\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- This behavior allows the code consuming the generator to take action after each yield expression in the coroutine. The consuming code can use the generator's output values to call other functions and update data structures. MOst importantly, it can advance other generator functions until their nexy yield expressions. By advancing many separate generators in lockstep, they will all seem to be running simultaneously, mimicking the concurrent behavior of Python threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The game of life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let me demonstrate the simultaneous behavior of coroutines with an example. Say you want to use coroutines to implement Conway's Game of Life. The rules of the game are simple. You have a two-dimensional grid of an arbitrary size. Each cell in the grid can either be alive or empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALIVE = '*'\n",
    "EMPTY = '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The game progresses one tick of the clock at a time. At each tick, each cell counts houw many of its neighboring eight cells are still alive. Based on its neighbor count, each cell decides if it will keep living, die, or regenerate. Here's an example of 5 x 5 Game of Life grid after four generations with time going to the right. I'll explain the specific rules further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I can model this game by representing each cell as a generator coroutine running in lockstep with all the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To implement this, first I need a way to retrieve the status of neighboring cells. I can do this with a coroutine named count\\_neighbors that works by yielding Query objects. The Query class I define myself. Its purpose is to provide the generator coroutine with a way to ask its surrounding environment for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Query = namedtuple('Query', ('y', 'x'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The coroutine yields a Query for each neighbor. The result of each yield expression will be the value ALIVE or EMPTY. That's the interface contract I've defined between the coroutine and its consuming code. The count\\_neighbors generator sees the nneighbors' states and returns the count of living neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_neighbors(y, x):\n",
    "    n_ = yield Query(y + 1, x + 0)\n",
    "    ne = yield Query(y + 1, x + 1)\n",
    "    e_ = yield Query(y + 0, x + 1)\n",
    "    se = yield Query(y + 1, x + 1)\n",
    "    s_ = yield Query(y - 1, x + 0)\n",
    "    sw = yield Query(y - 1, x - 1)\n",
    "    w_ = yield Query(y + 0, x - 1)\n",
    "    nw = yield Query(y + 1, x - 1)\n",
    "    \n",
    "    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]\n",
    "    count = 0\n",
    "    for state in neighbor_states:\n",
    "        if state == ALIVE:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I can drive the count\\_neighbors coroutine with fake data to test it. Here, I show how Query objects will be yielded for each neighbor. count\\_neighbors expects to receive cell states corresponding to ech Query through the coroutine's send method. The final count is returned in the StopIteration exception that is raised when the generator is exhausted by the return statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First yield:   Query(y=11, x=5)\n",
      "Second yield: Query(y=11, x=6)\n",
      "Third yield: Query(y=10, x=6)\n",
      "Fourth yield: Query(y=11, x=6)\n",
      "Fifth yield: Query(y=9, x=5)\n",
      "Sixth yield: Query(y=9, x=4)\n",
      "Seventh yield: Query(y=10, x=4)\n",
      "Eighth yield: Query(y=11, x=4)\n",
      "Count:  7\n"
     ]
    }
   ],
   "source": [
    "it = count_neighbors(10, 5)\n",
    "q1 = next(it)\n",
    "print('First yield:  ', q1)\n",
    "q2 = it.send(ALIVE)\n",
    "print('Second yield:', q2)\n",
    "q3 = it.send(ALIVE)\n",
    "print('Third yield:', q3)\n",
    "q4 = it.send(ALIVE)\n",
    "print('Fourth yield:', q4)\n",
    "q5 = it.send(ALIVE)\n",
    "print('Fifth yield:', q5)\n",
    "q6 = it.send(ALIVE)\n",
    "print('Sixth yield:', q6)\n",
    "q7 = it.send(ALIVE)\n",
    "print('Seventh yield:', q7)\n",
    "q8 = it.send(ALIVE)\n",
    "print('Eighth yield:', q8)\n",
    "try:\n",
    "    count = it.send(EMPTY)\n",
    "except StopIteration as e:\n",
    "    print('Count: ', e.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now I need the ability to indicate that a cell will transition to a new state in response to the neighbor count that it found from count\\_neighbors. To do this, I define another coroutine called step\\_cell. This generator will indicate transitions in a cell's state by yielding Transition objects. This is another class that I define, just like the Query class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The step\\_cell coroutine receives its coordinates in the grid as arguments. It yields a Query to get the initail state of those coordinates. It runs count\\_neighbors to inspect the celss around it. It runs the game logic to determine what state the cell should have for next clock tick. Finally, it yields a Transition object to tell the environment the cell's next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_logic(state, neighbors):\n",
    "    #...\n",
    "    pass\n",
    "    \n",
    "def step_cell(y, x):\n",
    "    state = yield Query(y, x)\n",
    "    neighbors = yield from count_neighbors(y, x)\n",
    "    next_state = game_logic(state, neighbors)\n",
    "    yield Transition(y, x, next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importantly, the call to count\\_neighbors uses the yield from expression. This expression allows Python to compose generator coroutines together, making it easy to reuse smaller pieces of functionality and build complex coroutines from simpler ones. When count\\_neighbors is exhausted, the final value it returns will be passed to step\\_cell as the result of the yield from expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_logic(state, neighbors):\n",
    "    if state == ALIVE:\n",
    "        if neighbors < 2:\n",
    "            return EMPTY \n",
    "        elif neighbors > 3:\n",
    "            return EMPTY\n",
    "    else:\n",
    "        if neighbors == 3:\n",
    "            return ALIVE\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I can drive the step\\_cell coroutine with fake data to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step_cell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1aebd97bfa94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mq0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Me:      '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Q1:      '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'step_cell' is not defined"
     ]
    }
   ],
   "source": [
    "it = step_cell(10, 5)\n",
    "q0 = next(it)\n",
    "print('Me:      ', q0)\n",
    "q1 = it.send(ALIVE)\n",
    "print('Q1:      ', q1)\n",
    "t1 = it.send(EMPTY)\n",
    "print('Outcome: ', t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- The goal of the game is to run this logic for a whole grid of cells in lockstep. To do this, I can further compose the step\\_cell coroutine into a simulate coroutine. This coroutine progresses the grid of cells forward by yielding from step\\_cell many times. After progressing every coordinate, it yields a TICK object to indicate that the current generation of cells have all trasitioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TICK = object()\n",
    "\n",
    "def simulate(height, width):\n",
    "    while True:\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                yield from step_cell(y, x)\n",
    "        yield TICK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's imporessive about simulate is that it's completely disconnected from the surrounding environmnet. I still haven't defined how the grid is represented in Python objects, how Query, Transitioin, and TICK values are handled on the outside, nor how the game gets its initail state. But the logic is clear. Eack cell will transition by running step\\_cell. Then the game clock will tick. This will continue forever, as long as the simulate coroutine is advanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the beauty of coroutines. They help you focus on the logic of what you're trying to accomplich. They decouple your code's instructions for the environment from the implementation that carries out your wishes. This enables you to run coroutines seemingly in parallel. This also allows you to improve the implementation of following those instructions over time without changing the coroutines.\n",
    "- Now, I want to run simulate in a real environment. To do that, I need to represent the state of each cell in the grid. Here, I define a class to contain the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Grid(object):\n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.rows = []\n",
    "        for _ in range(self.height):\n",
    "            self.rows.append([EMPTY] * self.width)\n",
    "        \n",
    "    def __str__(self):\n",
    "        #...\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The grid allows you to get and set the value of any coordinate. Coordinates that are out of bounds will wrap around, making the grid act like infinite looping space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query(self, y, x):\n",
    "    return self.rows[y & self.height][x % self.width]\n",
    "\n",
    "def assign(self, y, x, state):\n",
    "    self.rows[y % self.height][x % self.width] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At last, I can define the function that interprets the values yielded from simulate and all of its interior coroutines. This function turns the instructions from the coroutines into interactions with the surrounding environment. It progresses the whole grid of cells forward a single step and then returns a new grid  containing the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def live_a_generatioin(grid, sim):\n",
    "    progeny = Grid(grid.height, grid.width)\n",
    "    item = next(sim)\n",
    "    while item is not TICK:\n",
    "        if isinstance(item, Query):\n",
    "            state = grid.query(item.y, item.x)\n",
    "            item = sim.send(state)\n",
    "        else:\n",
    "            progeny.assign(item.y, item.x, item.state)\n",
    "            item = next(sim)\n",
    "    return progeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EMPTY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4f12aff5fcdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-a8419cda8fd5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, height, width)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEMPTY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EMPTY' is not defined"
     ]
    }
   ],
   "source": [
    "grid = Grid(5, 9)\n",
    "grid.assign(0, 3, ALIVE)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To see this function in action, I need to create a grid and set its initial state. Here, I make a classic shape called a glider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now I can progress this grid forward one generation at a time. You can see how the glider moves down and to the right on the grid based on the simple rules from the game\\_logic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnPrinter(object):\n",
    "    pass\n",
    "\n",
    "columns = ColumnPrinter()\n",
    "sim = simulate(grid.height, grid.width)\n",
    "for i in range(5):\n",
    "    columns.append(str(grid))\n",
    "    grid = live_a_generation(grid, sim)\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best part about this approach is that I can change the game\\_logic function without having to update the code that surrounds it. I can change the rules or add larger spheres of influence with the existing mechanics of Query, Transition, and TICK. This demonstrates how coroutines enable the separation of concerns, which is an important design principle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coroutines provide an efficient way to run tens of thousands of functions seemingly at the same time.\n",
    "- Within a generator, the value of the yield expression will be whatever value was passed to the generator's send method from the exterior code.\n",
    "- Coroutines give you a powerful tool for separating the core logic of your program from tis interaction with the surrounding environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I41 : Consider concurrent.futures for True Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At some point in writing Python programs, you may hit the performace wall. Even after optimizing your code, your program's execution may still be too slow for your needs. On modern computers that have an increasing number of CPU cores, it's reasonable to assume that one solution would be parallelism. What if you could split your code's computation into independent pieces of work taht run simultaneously across multiple CPU cores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unfortunately, Python's global interpreter lock (GIL) prevents true parallelism in threads, so that option is out. Another common suggestion is to rewrite your most performance-critical code as an extension module using the C language. C gets you closer to the bare metal and can run faster than Python, eliminating the need for parallelism. C-extensions can also start native threads that run in parallel and utilize multiple CPU cores. Python's API for C-extensions is well documented and a good choice for an escape hatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But rewriting your code in C has a high cost. Code that is short and understandable in Python can become verbose and complicated in C. Such a port requires extensive testing to ensure that the functionality is equivalent to the original Python code and that no bugs have been introduced. Sometimes it's worth it, which explains the large ecosystem of C-extension modules in the Python community that speed up things like text parsing, image compositing, and matrix math. There are even open source tools such as CPython and Numba that can ease the transition to C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem is that moving one piece of your program to C isn't sufficient most of the time. Optimized Python programs usually don't have one major source of slowness, but rather, there are often many significant contributors. To get the benefits of C's bare metal and threads, you'd need to port large parts of your program, drastically increasing testing needs and risk. There must be a better way to preserve your investment in Python to solve difficult computational probles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The multiprocessing built-in module, easily accessed via the concurrent.futures built-in module, may be exactly what you need. It enables Python to utilize multiple CPU cores in parallel by running additional interpreters as child processes. These child processes are separate from the main interpreter, so their global interpreter locks are also separate. Each child can fully utilize one CPU core. Each child has a link to the main process where it receives instructions to do computation and returns results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, say you want to do something computationally intensive with Python and utilize multiple CPU cores. I'll use an implementation of finding the greatest common divisor of two numbers as a proxy for a more computationally intense algorithm, like simulating fluids dynamics with the Navier-Stokes equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gcd(pair):\n",
    "    a, b = pair\n",
    "    low = min(a, b)\n",
    "    for i in range(low, 0, -1):\n",
    "        if a % i == 0 and b % i == 0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.465 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "numbers = [(1963309, 2265973), (2030677, 3814172), \n",
    "           (1551645, 2229620), (2039045, 2020802)]\n",
    "start = time()\n",
    "results = list(map(gcd, numbers))\n",
    "end = time()\n",
    "print('Took %.3f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running this code on multiple Python threads will yield no speed improvement because the GIL prevents Python from using multiple CPU cores in parallel. Here, I do the same computation as above using the concurrent.futures module with its ThreadPoolExecutor class and two worker threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.461 seconds\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "start = time()\n",
    "pool = ThreadPoolExecutor(max_workers=2)\n",
    "results = list(pool.map(gcd, numbers))\n",
    "end = time()\n",
    "print('Took %.3f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It;s even slower this time because of the overhead of starting and communicating with the pool of threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now for the surprising part: By changing a single line of code, something magical happens. If I replace the ThreadPoolExecutor with the ProcessPoolExecutor from the concurrent.futures module, everything speeds up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.386 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "pool = ProcessPoolExecutor(max_workers=2)\n",
    "results = list(pool.map(gcd, numbers))\n",
    "end = time()\n",
    "print('Took %.3f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running on my dual-core machine, it's significantly faster! How is this possible? Here's what the ProcessPoolExecutor class actually does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It takes each item from the numbers input data to map.\n",
    "2. It serializes it into binary data using the pickle module\n",
    "3. It copies the serialized data from the main interpreter process to a child interpreter process over a local socket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Next, it deserializes the data back into Python objects using pickle in the child process\n",
    "5. It then imports the Python module containing the gcd function.\n",
    "6. It runs the function on the input data in parallel with other child processes.\n",
    "7. It serializes the result back into bytes\n",
    "8. It copies those bytes back through the socket\n",
    "9. It deserializes the bytes back into Python objects in the parent process.\n",
    "10. Finally, it merges the results from multiple children into a single list to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although it looks simple to the programmer, the multiprocesing module and ProcessPoolExecutor class do a huge amount of work to make parallelism possible. In most other languages, the only touch point you need to coordinate two threads is a single lock or atomic operation. The overhead of using multiprocessing is high because of all of the serialization and deserialization that must happen between the parent and child processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This scheme is well suited to certain types of isolated, high-leverage tasks. By isolated, I mean functions that don't need to share state with other parts of the program. By high-leverage, I mean situations in which only a small amount of data must be transferred between the parent and child processes to enable a large amount of computaion. The greatest common deniminator algorithm is one example of this, but many other mathematical algorithms work similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If your computaion doesn't have these characteristics, then the overhead of multiprocessing may prevent it from speeding up your program through parallelization. When that happens, multiprocessing provides more advanced facilities for shared memory, cross-process locks, queues, and proxies. But all of these features are very complex. It's hard enough to reason about such tools in the memory space of a single process shared between Python threads. Extending that complexity to other processes and involving sockets makes this much more difficult to understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I suggest avoiding all parts of multiprocessing and using these features via the simpler concurrent.futures module. You can start by using the ThreadPoolExecutor class to run isolated, high-leverage functions in threads. Later, you can move to the ProcessPoolExecutor to get a speedup. Finally, once you've completely exhausted the other options, you can consider using the multiprocessing module directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Remember\n",
    "- Moving CPU bottlenecks to C-extension modules can be effective way to improve performance while maximizing your investment in Python code. However, the cost of doing so is high and may introduce bugs.\n",
    "- The multiprocessing module provides powerful tools that can parallelize certain types of Python computation with minimal effort.\n",
    "- The power of multiprocessing is best accessed through the concurrent.futures built-in module and its simple ProcessPoolExecutor class.\n",
    "- The advanced parts of the multiprocessing module should be avoided because they are so complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
