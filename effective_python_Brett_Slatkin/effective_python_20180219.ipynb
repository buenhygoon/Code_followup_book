{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I55 : Use repr Strings for Debugging Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When debuggin a Python program, the print function (or output via the logging built-in module) will get you surprisingly far. Python internals are often easy to access via plain attriutes. All you need to do is print how the state of your program changes while it runs and see where it goes wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The print function outputs a human-readable string version of whatever you supply it. For example, priting a basic string will print the contents of the string without the surrounding quote characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo bar\n"
     ]
    }
   ],
   "source": [
    "print('foo bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is equivalent to using the '%s' format string and the % operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo bar\n"
     ]
    }
   ],
   "source": [
    "print('%s' % 'foo bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem is that the human -readable string for a value doesn't make it clear what the actual type of the value is. For example, notice how in the default output of print you can't distinguish between the types of the number 5 and the string '5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(5)\n",
    "print('5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you're debuggin a program with print, these type differences matter. What you almost always want while debugging is to see the repr version of an object. The repr built-in function returns the *printable representation* of an object, which should be its most clearly understandable string representation. For built-in types, the string returned by repr is a valid Python expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\x07'\n"
     ]
    }
   ],
   "source": [
    "a = '\\x07'\n",
    "print(repr(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passing the value from repr to the eval built-in function should result in the same Python object you started with(of course, in practice, you should only use eval with extreme caution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = eval(repr(a))\n",
    "assert a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you're debugging with print, you should repr the value before printing to ensure that any difference in types is clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "'5'\n"
     ]
    }
   ],
   "source": [
    "print(repr(5))\n",
    "print(repr('5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is equivalent to using the '%r' format string and the % operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "'5'\n"
     ]
    }
   ],
   "source": [
    "print('%r' % 5)\n",
    "print('%r' % '5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For dynamic Python objects, the default human-readable string value is the same as teh repr value. This means that passing a dynamic object to print will do the right thing, and you don't need to explicitly call repr on it. Unfortunately, the default value of repr for object instances isn't especially helpful. For example, here I define a simple class and then print its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.OpaqueClass object at 0x7f4d8e840128>\n"
     ]
    }
   ],
   "source": [
    "class OpaqueClass(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "obj = OpaqueClass(1, 2)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This output can't be passed to the eval function, and it says nothing about the instance fields of the object. \n",
    "- There are two solutions to this problem. If you have control of the class, you can define your own \\_\\_repr\\_\\_ special method that returns a string containing the Python expression that recreates the object. Here, I define that function for the class above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BetterClass(1, 2)\n"
     ]
    }
   ],
   "source": [
    "class BetterClass(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'BetterClass(%d, %d)' % (self.x, self.y)\n",
    "    \n",
    "obj = BetterClass(1, 2)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you don't have control over the class definition, you can reach into the object's instance dictionary, which is stored in the \\_\\_dict\\_\\_ attribute. Here, I print out the contents of an OpaqueClass instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 4, 'y': 5}\n"
     ]
    }
   ],
   "source": [
    "obj = OpaqueClass(4, 5)\n",
    "print(obj.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Remember\n",
    "- Calling print on built-in Python types will produce the human-readable string version of a value, which hides type information.\n",
    "- Callling repr on built-in Python types will produce the printable string version of a value. These repr strings could be passed to the eval built-in function to get back the original value.\n",
    "- %s in format strings will produce human-readable strings like str.%r will produce printable strings like repr.\n",
    "- You can define the \\_\\_repr\\_\\_ method to customize the printable representation of a class and provide more detailed debugging information.\n",
    "- You can reach into any objecy's \\_\\_dict\\_\\_ attribute to view its internals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I56 : Test Everything with unittest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python doesn't have static type checking. There's nothings in the compiler that will ensure that your program will work when you run it. With Python you don't know whether the functions your programs calls will be defined at runtime, even when their existence is evident in the source code. This dynamic behavior is a blessing and a curse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The large numbers of Python programmers out there say it's worth it because of the productivity gained from the resulting brevity and simplicity. But more people have heard at least one horror story about Python in which a program encounted a boneheaded error at runtime.\n",
    "\n",
    "- One of the worst examples I've heard is when SyntaxError was raised in production as a side effect of a dynamic import. The programmer I know who was hit by this surprising occurrence has since ruled out using Python ever again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But I have to wonder, why wasn't the code tested before the program was deployed to production? Type safety isn't everything. You should always test your code, regardless of what language it's written in. However, I'll admit that the big difference between Python and many other languages is that the only way to have *any* confidence in Python program is by writing tests. There is no veil of static type checking to make you feel safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Luckily, the same dynamic features that prevent static type checking in Python also make it extremely easy to write tests for your code. You can use Python's dynamic nature and easily overridable behaviors to implement tests and ensure that your programs work as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You should think of tests as ana insurance policy on your code. Good tests give you confidence that your code is correct. If you refactor or expand your code, tests make it easy to identify how behaviors have changed. It sounds counter-intuitive, but having good tests actually makes it easier to modify Python code, not harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The simplest way to write tests is to use the unittest built-in module. For example, say you have the following utility function defined in utils.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_str(data):\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    elif isinstance(data, bytes):\n",
    "        return data.decode('utf-8')\n",
    "    else:\n",
    "        raise TypeError('Must supply str or bytes, '\n",
    "                        'found: %r' % data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To define tests, I create a second file named test\\_utils.py or utils\\_test.py that contains tests for each behavior I expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /home/dockeruser/ (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/home/dockeruser/'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dockeruser/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from unittest import TestCase, main\n",
    "# from utils import to_str\n",
    "\n",
    "class UtilsTestCase(TestCase):\n",
    "    def test_to_str_bytes(self):\n",
    "        self.assertEqual('hello', to_str(b'hello'))\n",
    "        \n",
    "    def test_to_str_str(self):\n",
    "        self.assertEqual('hello', to_str('hello'))\n",
    "        \n",
    "    def test_to_str_bad(self):\n",
    "        self.assertRaises(TypeError, to_str, object())\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tests are organized into TestCase classes. Each test is a method beginning with the word test. If a test method runs without raising any kind of Exception (including AssertionError from assert statements), then the test is considered to have passed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The TestCase class provides helper mehtods for making assertions in your test, such as assertEqual for verifying eqaulity, assertTrue for verifying Boolean expressions, and assertRaises for verifying that exceptions are raised when appropriate. You can define your own helper methods in TestCase subclasses to make your tests more readable; just ensure that your method names don't begin with the word test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes, your TestCase classes need to set up the test environment before running test methods. To do this, you can override the setUp and tearDown methods. These methods are called before and after each test method, respectively, and they let you ensure that each test runs in isolation. For example, here I define a TestCase that creates a temporary directory before each test and deletes its contents after each test finishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyTest(TestCase):\n",
    "    def setUp(self):\n",
    "        self.test_dir = TemporaryDirectory()\n",
    "    \n",
    "    def tearDown(self):\n",
    "        self.test_dir.cleanup()\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I usually define one TestCase for each set of related tests. Sometimes I have one TestCase for each function taht has many edge cases. Other times, a TestCase spans all functions in a single module. I'll also create one TestCase for testing a single class and all of its methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When programs get complicated, you'll want additional tests for verifying the interactions between your modules, instead of only testing code in isolation. This is the difference between *unit tests* and *integration tests*. In Python, it's important to write both types of tests for exactly the same reason: You have no guarantee that your modules will actually work together unless you prove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Remeber \n",
    "- The only way to have confidence in Python program is to write tests.\n",
    "- The unittest built-in module provides most of the facilities you'll need to write good tests.\n",
    "- You can define tests by subclassing TestCase and defineing one method per behavior you'd like to test. Test methods on TestCase classes must start with the word test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's important to write both unit tests and integration tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
