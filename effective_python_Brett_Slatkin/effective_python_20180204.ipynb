{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I39 : Use Queue to Coordinate Work Between Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python programs taht do many things concurrently often need to coordinate their work. One of the most useful arrangements for concurrent work is a pipeline of functions. \n",
    "\n",
    "- A pipeline works like an aseembly line used in manufacturing. Pipilines have many phases in serial with a specific function for each phase. New pieces of work are constantly added to the beginning of the pipeline. Each function can operate concurrently on the piece of work in tis phase. The work moves forward as each function completes until there are no subprocesses - acitivities that can easily be parallelized using Python./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, say you want to build a system that will take a constant stream of images from your digital camera, resize them, and then add them to a photo gallery online. Such a program could be split into three phases of a pipeline. New images are retrieved in the first phase. The downloaded images are passed through the resize function in the second phase. The resized images are consumed by the upload function in the final phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imagine you had already written Python functions that execute the phases: download, resize, upload. How do you assemble a pipeline to do the work concurrently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first thing you need is a way to hand off work between the pipeline phases. This can be modeled as a thread-safe producer-consumer queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from threading import Lock\n",
    "\n",
    "class MyQueue(object):\n",
    "    def __init__(self):\n",
    "        self.items = deque()\n",
    "        self.lock = Lock()\n",
    "        \n",
    "    def put(self, item):\n",
    "        with self.lock:\n",
    "            self.items.append(item)\n",
    "            \n",
    "    def get(self):\n",
    "        with self.lock:\n",
    "            return self.items.popleft()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, I represent each phase of the pipeline as a Python thread that takes \n",
    "work from one queue like this, runs a function on it, and puts the result on another queue. I also track how many times the worker has checked for new input and how much work it's completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "class Worker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        self.polled_count = 0\n",
    "        self.work_done = 0\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            self.polled_count += 1\n",
    "            try:\n",
    "                item = self.in_queue.get()\n",
    "            except IndexError:\n",
    "                sleep(0.01) \n",
    "            else:\n",
    "                result = self.func(item)\n",
    "                self.out_queue.put(result)\n",
    "                self.work_done += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The trichiest part is that the worker thread must properly handle the case where the input queue is empty because the previous phase hasn't complated its work yet. This happens where I catch the IndexError exception below. You can think of this as a holdup in the assembly line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now I can connect the three phases together by creating the queues for their coordination points and the corresponding worker threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    pass\n",
    "\n",
    "def resize():\n",
    "    pass\n",
    "\n",
    "def upload():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_queue = MyQueue()\n",
    "resize_queue = MyQueue()\n",
    "upload_queue = MyQueue()\n",
    "done_queue = MyQueue()\n",
    "threads = [\n",
    "    Worker(download, download_queue, resize_queue),\n",
    "    Worker(resize, resize_queue, upload_queue),\n",
    "    Worker(upload, upload_queue, done_queue)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I can start the threads and then inject a bunch of work into the first phase of the pipeline. Here, I use a plain object instance as a proxy for the real data required by the download function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dockeruser/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-2-4de27a683eb0>\", line 21, in run\n",
      "    result = self.func(item)\n",
      "TypeError: download() takes 0 positional arguments but 1 was given\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thread in threads:\n",
    "    thread.start()\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-1ba0b87de737>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-1ba0b87de737>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    # ...\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "while len(donw_queue.items) < 1000:\n",
    "    # do something useful while waiting\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This runs properly, but there's an interesting side effect caused by the threads polling their input queues for new work. The tricky part, where I catch IndexError exceptions in the run methods, executes a large number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 items after polling 371 times\n"
     ]
    }
   ],
   "source": [
    "processed = len(done_queue.items)\n",
    "polled = sum(t.polled_count for t in threads)\n",
    "print('Processed', processed, 'items after polling',\n",
    "    polled, 'times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- When the worker functions vary in speeds, an earlier phase can prevent progress in later phases, backing up the pipeline. This causes later phases to starve and constantly check their input queues for new work in a tight loop. The outcome is that worker threads waster CPU time doing nothing useful.\n",
    "\n",
    "- But that's just the beginning of what's wrong with this implementation. There are three more problems that you should also avoid. First, determining that all of the input work is complete requires yet another busy wait on the done\\_queue. Second, in Worker the run method will execute forever in its busy loop. There's no way to signal to a worker thread that it's time to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Third, and worst of all, a bakcup in the pipeline can cause the program to crash arbitrarily. If the first phase makes rapid progress but the second phase makes slow progress, then the queue connecting the first phase to the second phase will constantly increase in size. The second phase won't be able to keep up. Given enough time and input data, the program will eventually run out of memory and die.\n",
    "\n",
    "- The lesson isn't that pipelines are bad; it's that it's hard to build a good producer-consumer queue yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Queue to the Rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Queue class from the queue built-in module provides all of the functionality you need to solve these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Queue eliminates the busy waiting in the worker by making the get method block until new data is available. For example, here I start a thread that waits for some input data on a queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer waiting\n",
      "Producer putting\n",
      "Consumer done\n",
      "Producer done\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print(\"Consumer waiting\")\n",
    "    queue.get()\n",
    "    print(\"Consumer done\")\n",
    "    \n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "print('Producer putting')\n",
    "queue.put(object())\n",
    "thread.join()\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even though the thread is running first, it won't finish until an item is put on the Queue instance and the get method has something to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To solve the pipeline backup issue, the Queue class lets you specify the maximum amount of pending work you'll allow between two phases. This buffer size causes calls to put to block when the queue is already full. For example, here I define a thread that waits for a while before consuming a queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer put 1\n",
      "start\n",
      "Consumer got 1\n",
      "Producer put 2\n",
      "Consumer got 2\n",
      "Producer done\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "queue = Queue(1)\n",
    "\n",
    "def consumer():\n",
    "    time.sleep(0.1)\n",
    "    print('start')\n",
    "    queue.get()\n",
    "    print('Consumer got 1')\n",
    "    queue.get()\n",
    "    print('Consumer got 2')\n",
    "    \n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "queue.put(object())\n",
    "print('Producer put 1')\n",
    "queue.put(object())\n",
    "print('Producer put 2')\n",
    "thread.join()\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer waiting\n",
      "Consumer waiting\n",
      "Conusmer working\n",
      "Consumer done\n",
      "Producer done\n"
     ]
    }
   ],
   "source": [
    "in_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    work= in_queue.get()\n",
    "    print('Conusmer working')\n",
    "    # Doing work\n",
    "    print('Consumer done')\n",
    "    in_queue.task_done()\n",
    "    \n",
    "Thread(target=consumer).start()\n",
    "\n",
    "in_queue.put(object())\n",
    "\n",
    "print('Producer waiting')\n",
    "\n",
    "in_queue.join()\n",
    "\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClosableQueue(Queue):\n",
    "    SENTINEL = object()\n",
    "    \n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return None\n",
    "                yield item\n",
    "            finally:                \n",
    "                self.task_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, I define an iterator for the queue that looks for this special object and stops iteration when it's found. This \\_\\_iter\\_\\_ method also calls tase\\_done at appropriate times, letting me track the progress of work on the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoppableWorker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        #...\n",
    "        pass\n",
    "        \n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, I re-create the set of worker threads using the new worker class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_queue = ClosableQueue()\n",
    "#...\n",
    "threads = [\n",
    "    StoppableWorker(download, download_queue, resize_queue),   \n",
    "    #..\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "thread.__init__() not called",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-14f0e6780f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdownload_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdownload_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thread.__init__() not called\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: thread.__init__() not called"
     ]
    }
   ],
   "source": [
    "for thread in threads:\n",
    "    thread.start()\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "download_queue.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyQueue' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-99506fc6a321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdownload_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresize_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresize_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mupload_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mupload_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyQueue' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "download_queue.join()\n",
    "resize_queue.close()\n",
    "resize_queue.join()\n",
    "upload_queue.close()\n",
    "upload_queue.join()\n",
    "print(done_queue.qsize(), 'items finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipelines are a great way to organize sequences of work that run concurrently using multiple Python threads.\n",
    "- Be aware of the many problems in building concurrent pipelines: busy waiting, stopping workers, and memory explosion.\n",
    "- The Queue class has all of the facilities you need to build robust pipelines: blocking operations, buffer sizes, and joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
